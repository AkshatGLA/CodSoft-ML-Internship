{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"C:\\\\Users\\\\AKSHAT SOMANI\\\\OneDrive\\\\Desktop\\\\home\\\\gla akshat somani\\\\codesoft\\\\AtmFraud\\\\archive(1)\\\\creditcard.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Explore the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Preprocessing\n",
    "# Assuming 'Class' is the target variable and the rest are features\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Identify categorical columns (if any) and numeric columns\n",
    "# In this dataset, there are no categorical columns; all columns are numeric\n",
    "numeric_columns = X.columns\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train models\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train_scaled, y_train)\n",
    "y_pred_decision_tree = decision_tree.predict(X_test_scaled)\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "y_pred_random_forest = random_forest.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Logistic Regression:\")\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(confusion_matrix(y_test, y_pred_decision_tree))\n",
    "print(classification_report(y_test, y_pred_decision_tree))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_decision_tree))\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(confusion_matrix(y_test, y_pred_random_forest))\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_random_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"C:\\\\Users\\\\AKSHAT SOMANI\\\\OneDrive\\\\Desktop\\\\home\\\\gla akshat somani\\\\codesoft\\\\AtmFraud\\\\archive(1)\\\\creditcard.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Explore the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Preprocessing\n",
    "# Assuming 'Class' is the target variable and the rest are features\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Identify categorical columns (if any) and numeric columns\n",
    "# In this dataset, there are no categorical columns; all columns are numeric\n",
    "numeric_columns = X.columns\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train models\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# # Decision Tree\n",
    "# Evaluate models\n",
    "print(\"Logistic Regression:\")\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "Logistic Regression:\n",
      "[[56851    13]\n",
      " [   36    62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.83      0.63      0.72        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.82      0.86     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Accuracy: 0.9991397773954567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"C:\\\\Users\\\\AKSHAT SOMANI\\\\OneDrive\\\\Desktop\\\\home\\\\gla akshat somani\\\\codesoft\\\\AtmFraud\\\\archive(1)\\\\creditcard.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Explore the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Preprocessing\n",
    "# Assuming 'Class' is the target variable and the rest are features\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Identify categorical columns (if any) and numeric columns\n",
    "# In this dataset, there are no categorical columns; all columns are numeric\n",
    "numeric_columns = X.columns\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train models\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Logistic Regression:\")\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the datasets\n",
    "train_data_path = \"C:\\\\Users\\\\AKSHAT SOMANI\\\\OneDrive\\\\Desktop\\\\home\\\\gla akshat somani\\\\codesoft\\\\AtmFraud\\\\fraudTrain.csv\"\n",
    "test_data_path = \"C:\\\\Users\\\\AKSHAT SOMANI\\\\OneDrive\\\\Desktop\\\\home\\\\gla akshat somani\\\\codesoft\\\\AtmFraud\\\\fraudTest.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Explore the datasets\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(train_data.isnull().sum())\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# Preprocessing\n",
    "# Assuming 'is_fraud' is the target variable and the rest are features\n",
    "X_train = train_data.drop('is_fraud', axis=1)\n",
    "y_train = train_data['is_fraud']\n",
    "X_test = test_data.drop('is_fraud', axis=1)\n",
    "y_test = test_data['is_fraud']\n",
    "\n",
    "# Drop irrelevant columns\n",
    "X_train = X_train.drop(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'first', 'last', 'street', 'city', 'state', 'zip', 'job', 'dob', 'trans_num'], axis=1)\n",
    "X_test = X_test.drop(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'first', 'last', 'street', 'city', 'state', 'zip', 'job', 'dob', 'trans_num'], axis=1)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = ['merchant', 'category', 'gender']\n",
    "numeric_columns = [col for col in X_train.columns if col not in categorical_columns]\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_columns]))\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test[categorical_columns]))\n",
    "\n",
    "# Restore column names after encoding\n",
    "X_train_encoded.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "X_test_encoded.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "\n",
    "# Reset index to match original data\n",
    "X_train_encoded.reset_index(drop=True, inplace=True)\n",
    "X_test_encoded.reset_index(drop=True, inplace=True)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine numeric and encoded categorical columns\n",
    "X_train_final = pd.concat([X_train[numeric_columns], X_train_encoded], axis=1)\n",
    "X_test_final = pd.concat([X_test[numeric_columns], X_test_encoded], axis=1)\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_final[numeric_columns] = scaler.fit_transform(X_train_final[numeric_columns])\n",
    "X_test_final[numeric_columns] = scaler.transform(X_test_final[numeric_columns])\n",
    "\n",
    "# Train models\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_final)\n",
    "\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train_final, y_train)\n",
    "y_pred_decision_tree = decision_tree.predict(X_test_final)\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train_final, y_train)\n",
    "y_pred_random_forest = random_forest.predict(X_test_final)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Logistic Regression:\")\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(confusion_matrix(y_test, y_pred_decision_tree))\n",
    "print(classification_report(y_test, y_pred_decision_tree))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_decision_tree))\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(confusion_matrix(y_test, y_pred_random_forest))\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_random_forest))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
